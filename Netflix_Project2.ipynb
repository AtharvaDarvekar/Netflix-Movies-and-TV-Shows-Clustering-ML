{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtharvaDarvekar/Netflix-Movies-and-TV-Shows-Clustering-ML/blob/main/Netflix_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member  -** Atharva Shirish Darvekar\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/AtharvaDarvekar/Netflix-Movies-and-TV-Shows-Clustering-ML"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "id": "rVoLXgSc8hSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "import contractions\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PevI6bx-rwOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "#import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "BzC4IJIDrXQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/drive/MyDrive/Colab Notebooks/Datasets/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "netflix_df = pd.read_csv(filepath)"
      ],
      "metadata": {
        "id": "S3wqXFlKgwj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "netflix_df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "netflix_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of rows in dataset :', netflix_df.shape[0])\n",
        "print('Number of rows in dataset :', netflix_df.shape[1])"
      ],
      "metadata": {
        "id": "k7i2005yhurr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "netflix_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "netflix_df[netflix_df.duplicated()]"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hence there are no duplicate values"
      ],
      "metadata": {
        "id": "8oTccmWsvebM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "netflix_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total null values\n",
        "netflix_df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "netflix_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "netflix_df.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show_id - Unique id for every movie / tv show  \n",
        "type - It takes value either movie or a tv show  \n",
        "title - Title of the movie / tv show  \n",
        "director - Director of the show  \n",
        "cast - Actors involved in the movie / tv show  \n",
        "country - Country of the production  \n",
        "date_added - Date on which it was added on netflix  \n",
        "release_year - Actual release year of the show  \n",
        "rating - TV rating of the show  \n",
        "duration - Total duration in minutes or number of seasons  \n",
        "listed_in - Genre of the show  \n",
        "description - Description of the show  \n"
      ],
      "metadata": {
        "id": "B0gnc2PkEaLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "all_columns = netflix_df.columns\n",
        "for col in all_columns:\n",
        "  print(f\"{col} : {netflix_df[col].nunique()}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "netflix_df['cast'].fillna(value='no_cast',inplace=True)\n",
        "netflix_df['country'].fillna(value=netflix_df['country'].mode()[0],inplace=True)\n",
        "netflix_df['director'].fillna(value='dir_unavailable',inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 10 and 7 missing values in date_added and rating column which are very low in number. So we drop these rows.\n",
        "netflix_df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "2vU97ynjYX9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_df.isnull().sum()"
      ],
      "metadata": {
        "id": "qnSeauUFZPYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_df.info()"
      ],
      "metadata": {
        "id": "F8CJbmOeZdVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I read the dataset using pandas read_csv() method. Then isnull() method is used to check for any null values. Null values are replaced with appropriate value which represents entire column. Director column is dropped due to its unnecessity. Hence our data is ready for data visualization."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 (Type of show and its corresponding count)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "type_df = netflix_df['type'].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_df"
      ],
      "metadata": {
        "id": "XFM1xQgqlHYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=type_df, x='type', y='count', hue='type')\n",
        "# plt.title('Count of listings in different groups')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M-iINqDCcNsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As type is a categorical variable, Bar plot is suitable for compairing values across different categories."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Netflix has 5372 movies and 2398 TV shows.\n",
        "*   There are more number movies on Netflix than TV shows.\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, There are less number of tv shows than movies on netflix. Hence netflix has focused on movies. So if a person who's more interested in tv shows may find less variety."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 (Number of movies/tv shows in terms of rating using lineplot)"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "rating_df = netflix_df['rating'].value_counts().reset_index()\n",
        "\n",
        "rating_df.columns"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df"
      ],
      "metadata": {
        "id": "4brXFPrnboPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,5))\n",
        "sns.pointplot(data= rating_df, x=\"rating\", y=\"count\")"
      ],
      "metadata": {
        "id": "3sOiPAwOYcoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line chart is used for showing trend in the dataset. Hence it is used here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   TV-MA has the highest number of ratings for movies or tv shows i,e adult ratings.\n",
        "*   Most of the movies / tv shows available on netflix are adult.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, There are less number of shows for kids and family.  "
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 (Number of movies/tv shows according to release year using horizontal barplot)"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "release_df = netflix_df['release_year'].value_counts()[:10].reset_index()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "release_df"
      ],
      "metadata": {
        "id": "pKRw_0Apgo3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=release_df, x='count', y='release_year', hue='count', orient='h')"
      ],
      "metadata": {
        "id": "N6JyB7ZjfPvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is generally used to compare values across different categories.\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Netflix have most of the movies / tv shows that are released in 2018.\n",
        "*   Netflix have fresh content because most of the movies on netflix have released between 2015 and 2020.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, Netflix have made new movies / tv shows available on platform because users are more interested in new movies."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 (Number of shows based on genre using horizontal barplot)"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "genre_df = netflix_df['listed_in'].value_counts()[:10].reset_index()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_df"
      ],
      "metadata": {
        "id": "kUY4iDu9jhpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=genre_df, x='count', y='listed_in', hue='count', orient='h')"
      ],
      "metadata": {
        "id": "HsxNgOuEjfTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is generally used to compare values across different categories."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   There are highest number of documentaries with 334 count followed by stand-up comedy shows with 321 count and so on.\n",
        "*   Children and family shows are on the lower side of the graph.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, There is a large variety of shows in terms of genre."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 (Top 15 countries with most content)"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "country_df = netflix_df['country'].value_counts().index[0:15]"
      ],
      "metadata": {
        "id": "WU3ze-4Hn-yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.countplot(x=netflix_df['country'], order= country_df, hue=netflix_df['type'])\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('Top 15 countries with most contents', fontsize=15, fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joint bar graph is used here because we have two types i.e. movie and tv show."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   United States has the highest number of content around 2000 movies and 1000 tv shows followed by India\n",
        "*   Netflix has most content in English laguage because of US and UK are among top three.\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, because most of the people know English even if there mother tongue is not English."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 (Duration distribution for movies)"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = netflix_df[netflix_df['type'] == 'Movie']"
      ],
      "metadata": {
        "id": "KxLoSMM-tVCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#Checking the distribution of Movie Durations\n",
        "plt.figure(figsize=(10,7))\n",
        "#Regular Expression pattern \\d is a regex pattern for digit + is a regex pattern for at leas\n",
        "sns.distplot(movies['duration'].str.extract('(\\d+)'),kde=False, color=['red'])\n",
        "plt.title('Distplot with Normal distribution for Movies',fontweight=\"bold\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram can be used to describe the range of duration of movies."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Most of the movies has duration between 50 and 150.\n",
        "*  Mean duration of the movies is 100 min.\n",
        "*  There are very less number of movies whose duration is greater than 200 min.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, because mean of the duration of movies is very good is 100 min."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 ( Duration distribution for tv shows)"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows = netflix_df[netflix_df['type'] == 'TV Show']"
      ],
      "metadata": {
        "id": "Q4uluiKgx0WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows['duration'].value_counts()"
      ],
      "metadata": {
        "id": "QZHJlHxbkod9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(30,6))\n",
        "plt.title(\"Distribution of TV Shows duration\",fontweight='bold')\n",
        "sns.countplot(x=tv_shows['duration'],data=tv_shows,order = tv_shows['duration'].value_counts().index)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram is used to describe the range of duration of movies."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Most of the tv shows (1606) have 1 season of duration.\n",
        "*   Tv shows with 2 seasons has a count of 378.\n",
        "*   There are only 1 or 2 tv shows which has seasons 11 or greater.\n",
        "*   There is huge difference of numbers between tv shows with 1 season and remaining others.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, because most of the tv shows shows has seasons 1, 2 or maximum 3. So it is less time consuming for users."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 ( Top 10 directors by number of movies/ tv shows using bar plot)"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Removing observations where the director is unavailable\n",
        "director_df = netflix_df[netflix_df['director'] != 'dir_unavailable']"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "director_count = director_df['director'].value_counts()[:10].reset_index()"
      ],
      "metadata": {
        "id": "ivdO0DrqsDbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "director_count"
      ],
      "metadata": {
        "id": "IJWAl651uryb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.barplot(data= director_count, x='director', y='count')\n",
        "plt.yticks(range(0, 20))\n",
        "plt.xticks(rotation = 25)"
      ],
      "metadata": {
        "id": "mlb5WW3JrhoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is suitable for comparing values across different categories."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Raul Campos and Jan Suter has directed most number of movies i.e. 18.\n",
        "*   They are followed by Marcus Raboy with 16 films directed, Jay Karas with 14 films directed and so on.\n",
        "*   Most famous directors all over the world i.e Martin Scorsese and Steven Spielberg have directed 12 and 10 movies respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, Directors all over the world contributed to provide great movies or tv shows."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "type_pie_df = netflix_df['type'].value_counts().reset_index()\n",
        "type_pie_df"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palette_color = sns.color_palette('bright')\n",
        "plt.pie(type_pie_df['count'], labels=type_pie_df['type'], colors=palette_color, autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pddUmGbglT5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we want show the contribution of each element, we use pie chart."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Movies have 69.1 % of share in pie chart.\n",
        "*   TV shows have 30.86 % of share in pie chart.\n",
        "*   There are more movies than TV shows in the dataset.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, There are no insights that lead to negative growth because even if there are more movies, there are considerable amount of tv shows also."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(netflix_df['release_year'])\n",
        "plt.title('distribution by released year')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "netflix_df[~(netflix_df['cast']=='no_cast') & (netflix_df['type']=='Movie')].cast.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Actors who have appeared in highest number of movies')"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to compare appearance of actors in movies hence bar chart is used."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Samuel West has appeared in 10 movies, followed by Jeff Dunham with 7 movies.\n",
        "*   There are 8 actors who has appeared in 5 movies.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "netflix_df[~(netflix_df['cast']=='no_cast') & (netflix_df['type']=='TV Show')].cast.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Actors who have appeared in highest number of TV shows')"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to compare appearance of actors in tv shows hence bar chart is used.\n",
        "\n"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   David Attenborough has appeared in 13 TV shows, followed by Michela Luci, Jamie Watson, Anna Claire Bartlam, Dante Zee, Eric Peterson with 4 TV shows.\n",
        "\n"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Building a wordcloud for the movie descriptions\n",
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "# iterate through the csv file\n",
        "for val in netflix_df.description.values:\n",
        "\n",
        "    # typecaste each val to string\n",
        "    val = str(val)\n",
        "\n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "\n",
        "    # Converts each token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 700, height = 700,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (10,5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we want to show which word has more frequency in description of movie of tv show hence word is used where word sizes are decided on there frequency."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Some keywords in Netflix show descriptions: life, family, new, love, young, world, group, death, man, woman, murder, son, girl, secret.\n",
        "\n"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the original dataset for clustering\n",
        "# Hence it does not require handling missing values\n",
        "df1 = netflix_df.copy()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.fillna('',inplace=True)"
      ],
      "metadata": {
        "id": "Bh6Q0DbOH7F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were total 5 columns which had missing values. Null values present in director and cast column were replaced by dir_unavailable and no_cast respectively. Null values in country column were replaced by mode of the country column. And rows with null values in date_added and rating column were dropped because they were very low in number."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the columns has textual data. Only two columns i.e. realease year and date_added have numerical data which is irrelevent. Hence handling outliers are not required."
      ],
      "metadata": {
        "id": "NCe1mbnhi_yi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Selecting the attributes"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "df1['clustering_attributes'] = (df1['director'] + ' ' +\n",
        "                                df1['cast'] +' ' +\n",
        "                                df1['country'] +' ' +\n",
        "                                df1['listed_in'] +' ' +\n",
        "                                df1['description'])"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][2]"
      ],
      "metadata": {
        "id": "u84RW1HGzYw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Removing non-Ascii characters"
      ],
      "metadata": {
        "id": "5XS-tEF6Fk2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing non-ASCII characters:\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Function to remove non-ASCII characters\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "NKdHCqRsFk2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove non-ascii characters\n",
        "df1['clustering_attributes'] = remove_non_ascii(df1['clustering_attributes'])"
      ],
      "metadata": {
        "id": "0V6R6zChFk2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "lVLKL29LFk2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_con(text):\n",
        "  new_text = contractions.fix(text)\n",
        "\n",
        "  return new_text"
      ],
      "metadata": {
        "id": "ahOG9h5c7x4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(expand_con)"
      ],
      "metadata": {
        "id": "PP4ZE9bC7xsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "0uApwcuG7xpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "def word_lower(words):\n",
        "    \"\"\"Function make words to lowercase\"\"\"\n",
        "    words_lower = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        words_lower.append(new_word)\n",
        "    return words_lower"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = word_lower(df1['clustering_attributes'])"
      ],
      "metadata": {
        "id": "WGBsV6da1Ujr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "Au98NIPC1Ucx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "# function to remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation marks\n",
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "Ju9mP8Bj1sL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "2pT8Yb541sJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing digits and words containing digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing URLs\n",
        "def remove_urls(text):\n",
        "    # Define a regex pattern to match URLs\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "\n",
        "    # Use the sub() method to replace URLs with the specified replacement text\n",
        "    text_without_urls = url_pattern.sub('', text)\n",
        "\n",
        "    return text_without_urls"
      ],
      "metadata": {
        "id": "yu9S572n4TDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(remove_urls)"
      ],
      "metadata": {
        "id": "kSJ0Wjhx4l5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "D6Hw5To16ZFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing digits and words containing digits\n",
        "def remove_digits(text):\n",
        "    '''a function for removing digits'''\n",
        "    translator = str.maketrans('', '', string.digits)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(remove_digits)"
      ],
      "metadata": {
        "id": "bblZHZCW2trv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "uCAjtkdV2tX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "# extracting the stopwords from nltk library\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "np.array(sw)"
      ],
      "metadata": {
        "id": "T2LSJh154s8W",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word for word in text.split() if word not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "WvKukdO1-Z-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(stopwords)"
      ],
      "metadata": {
        "id": "5u1HFQIB-q5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "YP_Mp14x-tYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to lemmatize the corpus\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "OE7rSNhiAjvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "df1['clustering_attributes'] = lemmatize_verbs(df1['clustering_attributes'])"
      ],
      "metadata": {
        "id": "eDw3qrNXAkc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "qbQ-8k2sAmyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used lemmatization instead of stemming because:\n",
        "*   Lemmatization looks at the meaning of the word and its context to produce more accurate base form where stemming only removes suffix from the word.\n",
        "*   Lemmatization can handle various inflections of the word including plural forms, verb tenses.\n",
        "*   Lemmatization always produces real words.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = TweetTokenizer()"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(lambda x: tokenizer.tokenize(x))"
      ],
      "metadata": {
        "id": "Uhdw3lQu_rze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "5dtaEsT-B-zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "# clustering tokens saved in a variable\n",
        "clustering_data = df1['clustering_attributes']"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "def identity_tokenizer(text):\n",
        "    return text\n",
        "\n",
        "# Using TFIDF vectorizer to vectorize the corpus\n",
        "# max features = 20000 to prevent system from crashing\n",
        "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False,max_features = 20000)\n",
        "X = tfidf.fit_transform(clustering_data)"
      ],
      "metadata": {
        "id": "fMXcTnixAMy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "tfOZIsITVjio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of X\n",
        "X.shape"
      ],
      "metadata": {
        "id": "1VzvEM_RAS-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data type of vector\n",
        "type(X)"
      ],
      "metadata": {
        "id": "rakdiTx8AWER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X into array form for clustering\n",
        "X = X.toarray()"
      ],
      "metadata": {
        "id": "dQciYyH-W9R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used TFIDF vectorization technique in place of BAG OF WORDS because TFIDF takes into account of each word in the document.TFIDF also assigns higher values to rare words that are unique to perticular document."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction is the process of reducing the number of features or dimensions in a dataset while retaining as much information as possible. The main goal of dimensionality reduction is to simplify the data while minimizing the loss of information. It is a crucial step in machine learning and data analysis as it can help to improve the performance of models, reduce overfitting, and make it easier to visualize and interpret the data."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   There are several techniques used for dimensionality reduction, such as: Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), t-Distributed Stochastic Neighbor Embedding (t-SNE), Autoencoder, and Random Projection etc.\n",
        "*   We will use Principal Component Analysis (PCA) to reduce the dimensionality of data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(random_state=42)\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "id": "ST7jQ_efwUp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance for different number of components\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - Cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')"
      ],
      "metadata": {
        "id": "NRbAZ-WRwZqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   We find that 100% of the variance is explained by about ~7500 components.\n",
        "*   Also, more than 80% of the variance is explained just by 4000 components.\n",
        "*   Hence to simplify the model, and reduce dimensionality, we can take the top 4000 components, which will still be able to capture more than 80% of variance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ff4xSs8Jwfy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 4000 using pca\n",
        "pca = PCA(n_components=4000,random_state=42)\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "id": "MavNGknzxD4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "x_pca = pca.transform(X)"
      ],
      "metadata": {
        "id": "9Gi2smLgxGwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of transformed vectors\n",
        "x_pca.shape"
      ],
      "metadata": {
        "id": "R-u2oGzkxGtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow method to find the optimal value of k\n",
        "wcss=[]\n",
        "for i in range(1,31):\n",
        "  kmeans = KMeans(n_clusters=i,init='k-means++',random_state=33)\n",
        "  kmeans.fit(X)\n",
        "  wcss_iter = kmeans.inertia_\n",
        "  wcss.append(wcss_iter)\n",
        "\n",
        "number_clusters = range(1,31)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(number_clusters,wcss)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')"
      ],
      "metadata": {
        "id": "DCpgedanYxRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sum of squared distance between each point and the centroid in a cluster (WCSS) decreases with the increase in the number of clusters."
      ],
      "metadata": {
        "id": "H1M4LMhZyP54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Silhouette score for different umber of clusters\n",
        "range_n_clusters = range(2,31)\n",
        "silhouette_avg = []\n",
        "for num_clusters in range_n_clusters:\n",
        "  # initialize kmeans\n",
        "  kmeans = KMeans(n_clusters=num_clusters,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  cluster_labels = kmeans.labels_\n",
        "\n",
        "  # silhouette score\n",
        "  silhouette_avg.append(silhouette_score(x_pca, cluster_labels))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range_n_clusters,silhouette_avg)\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B-Ywr1PoyNaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest Silhouette score is obtained for 6 clusters."
      ],
      "metadata": {
        "id": "_eOHJ6DAyYWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building 6 clusters using the k-means clustering algorithm:\n",
        "kmeans = KMeans(n_clusters=6,init='k-means++',random_state=33)\n",
        "kmeans.fit(x_pca)"
      ],
      "metadata": {
        "id": "XjtSeOkLyUyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(x_pca, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion,kmeans_silhouette_score))"
      ],
      "metadata": {
        "id": "icxUcs0WykaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df1['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "VgmcJNHfyvnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='kmeans_cluster',data=df1, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "_TLcHSFcyyER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def kmeans_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df1[df1['kmeans_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (10,5), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "yskbrTyPy0R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 0\n",
        "kmeans_worldcloud(0)"
      ],
      "metadata": {
        "id": "PLdv8LJ6y6_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 1\n",
        "kmeans_worldcloud(1)"
      ],
      "metadata": {
        "id": "kGbi6qh4y7sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "kmeans_worldcloud(2)"
      ],
      "metadata": {
        "id": "xInHTY3Cy7jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 3\n",
        "kmeans_worldcloud(3)"
      ],
      "metadata": {
        "id": "ivzuysa-y7f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 4\n",
        "kmeans_worldcloud(4)"
      ],
      "metadata": {
        "id": "md9QXNwDy7c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 5\n",
        "kmeans_worldcloud(5)"
      ],
      "metadata": {
        "id": "V-6bjV0EzI94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 (Hierarchical clustering:)"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide on the number of clusters\n",
        "plt.figure(figsize=(10, 7))\n",
        "dend = shc.dendrogram(shc.linkage(x_pca, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 3.8, color='r', linestyle='--')"
      ],
      "metadata": {
        "id": "2y9uzCaQzk7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At a distance of 3.8 units, 12 clusters can be built using the agglomerative clustering algorithm."
      ],
      "metadata": {
        "id": "qK2TCQ9bzuhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=12, affinity='euclidean', linkage='ward')\n",
        "hierarchical.fit_predict(x_pca)"
      ],
      "metadata": {
        "id": "VfvT8cahzrcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df1['hierarchical_cluster'] = hierarchical.labels_"
      ],
      "metadata": {
        "id": "nQ1Ns9Uxzxqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='hierarchical_cluster',data=df1, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "zeT-GqLDzzrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 12 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "gB-ufcs6z2O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def hierarchical_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df1[df1['hierarchical_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (10,5), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "6_KSvlPJz698"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 0\n",
        "hierarchical_worldcloud(0)"
      ],
      "metadata": {
        "id": "oxBPInUQz-XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 1\n",
        "hierarchical_worldcloud(1)"
      ],
      "metadata": {
        "id": "3dRhJ3Kpz-UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "hierarchical_worldcloud(2)"
      ],
      "metadata": {
        "id": "lkYtoDSvz-RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 3\n",
        "hierarchical_worldcloud(3)"
      ],
      "metadata": {
        "id": "c_jGjGAQz-Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 4\n",
        "hierarchical_worldcloud(4)"
      ],
      "metadata": {
        "id": "Qnu80NE8z-Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 5\n",
        "hierarchical_worldcloud(5)"
      ],
      "metadata": {
        "id": "-wOmt-qmz-Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 6\n",
        "hierarchical_worldcloud(6)"
      ],
      "metadata": {
        "id": "11SKfGs2z-E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 7\n",
        "hierarchical_worldcloud(7)"
      ],
      "metadata": {
        "id": "T5CKsEMpz-B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 8\n",
        "hierarchical_worldcloud(8)"
      ],
      "metadata": {
        "id": "TBkWSdIZz95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 9\n",
        "hierarchical_worldcloud(9)"
      ],
      "metadata": {
        "id": "R3W09ohP0GAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 10\n",
        "hierarchical_worldcloud(10)"
      ],
      "metadata": {
        "id": "W7-AhogW0F4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 11\n",
        "hierarchical_worldcloud(11)"
      ],
      "metadata": {
        "id": "6MbkjfsK0F1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 (Content based recommender system:)"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   We can build a simple content based recommender system based on the similarity of the shows.\n",
        "*   If a person has watched a show on Netflix, the recommender system must be able to recommend a list of similar shows that s/he likes.\n",
        "*   To get the similarity score of the shows, we can use cosine similarity.\n",
        "*   The similarity between two vectors (A and B) is calculated by taking the dot product of the two vectors and dividing it by the magnitude value as shown in the equation below. We can simply say that the CS score of two vectors increases as the angle between them decreases.\n",
        "*   cos(0) = A . B/ |A| . |B|\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wRBZiybV1JqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a new df for building a recommender system\n",
        "recommender_df = df1.copy()"
      ],
      "metadata": {
        "id": "O29d_yj31C71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the index of the df from show id to show title\n",
        "recommender_df['show_id'] = recommender_df.index"
      ],
      "metadata": {
        "id": "fQyPbsft2EaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting tokens to string\n",
        "def convert(lst):\n",
        "  return ' '.join(lst)\n",
        "\n",
        "recommender_df['clustering_attributes'] = recommender_df['clustering_attributes'].apply(lambda x: convert(x))"
      ],
      "metadata": {
        "id": "z2YdtQaE2FLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting title of movies/Tv shows as index\n",
        "recommender_df.set_index('title',inplace=True)"
      ],
      "metadata": {
        "id": "DV6DiTw-2G2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count vectorizer\n",
        "CV = CountVectorizer()\n",
        "converted_matrix = CV.fit_transform(recommender_df['clustering_attributes'])"
      ],
      "metadata": {
        "id": "hOBNMCFu2Ioj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity\n",
        "cosine_similarity = cosine_similarity(converted_matrix)"
      ],
      "metadata": {
        "id": "2m4bafyS2L35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity.shape"
      ],
      "metadata": {
        "id": "3WlzSWhA2MXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a function to get 10 recommendations for a show\n",
        "indices = pd.Series(recommender_df.index)\n",
        "\n",
        "def recommend_10(title, cosine_sim = cosine_similarity):\n",
        "  try:\n",
        "    recommend_content = []\n",
        "    idx = indices[indices == title].index[0]\n",
        "    series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "    top10 = list(series.iloc[1:11].index)\n",
        "    # list with the titles of the best 10 matching movies\n",
        "    for i in top10:\n",
        "      recommend_content.append(list(recommender_df.index)[i])\n",
        "    print(\"If you liked '\"+title+\"', you may also enjoy:\\n\")\n",
        "    return recommend_content\n",
        "\n",
        "  except:\n",
        "    return 'Invalid Entry'"
      ],
      "metadata": {
        "id": "oVk79Hfa2QyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Stranger Things'\n",
        "recommend_10('Stranger Things')"
      ],
      "metadata": {
        "id": "rWW4TDcn2UtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Peaky Blinders'\n",
        "recommend_10('Peaky Blinders')"
      ],
      "metadata": {
        "id": "ex6Lmq8r2UqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Lucifer'\n",
        "recommend_10('Lucifer')"
      ],
      "metadata": {
        "id": "36qq6huO2UcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'ABC'\n",
        "recommend_10('ABC')"
      ],
      "metadata": {
        "id": "WT7dFgD52aHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have chosen Silhoutte Score over Distortion Score (also known as inertia or sum of squared distances) as evaluation metrics as it measures how well each data point in a cluster is separated from other clusters. It ranges from -1 to 1, with higher values indicating better cluster separation. A silhouette score close to 1 indicates that the data point is well-matched to its own cluster and poorly matched to neighboring clusters. A score close to 0 indicates that the data point is on or very close to the boundary between two clusters. A score close to -1 indicates that the data point is probably assigned to the wrong cluster.\n",
        "\n",
        "The advantages of using silhouette score over distortion score are:\n",
        "\n",
        "*   Silhouette score takes into account both the cohesion (how well data points within a cluster are similar) and separation (how well data points in different clusters are dissimilar) of the clusters, whereas distortion score only considers the compactness of each cluster.\n",
        "*   Silhouette score is less sensitive to the shape of the clusters, while distortion score tends to favor spherical clusters, and in our case the clusters are not completely spherical.\n",
        "*   Silhouette score provides more intuitive and interpretable results, as it assigns a score to each data point rather than just a single value for the entire clustering solution.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have considered K-means as our final model, as we are getting the comparatevely high Silhoutte Score in K-means clustering and the resulted clusters are very well seperated from each others as have saw in the 3 dimensions.\n",
        "\n",
        "Also in some of the situations K-means works more accurately then other clustering methods such as:\n",
        "\n",
        "*   Speed: K-means is generally faster than hierarchical clustering, especially when dealing with large datasets, since it involves fewer calculations and iterations.\n",
        "*   Ease of use: K-means is relatively straightforward to implement and interpret, as it requires only a few parameters (such as the number of clusters) and produces a clear partitioning of the data.\n",
        "*   Scalability: K-means can easily handle datasets with a large number of variables or dimensions, whereas hierarchical clustering becomes computationally expensive as the number of data points and dimensions increase.\n",
        "*   Independence of clusters: K-means produces non-overlapping clusters, whereas hierarchical clustering can produce overlapping clusters or clusters that are nested within each other, which may not be ideal for certain applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   In this project, we worked on a text clustering problem wherein we had to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other.\n",
        "*   The dataset contained about 7787 records, and 12 attributes.\n",
        "We began by dealing with the dataset's missing values and doing exploratory data analysis (EDA).\n",
        "*   It was found that Netflix hosts more movies than TV shows on its platform, and the total number of shows added on Netflix is growing exponentially. Also, majority of the shows were produced in the United States, and the majority of the shows on Netflix were created for adults and young adults age group.\n",
        "*   It was decided to cluster the data based on the attributes: director, cast, country, genre, and description. The values in these attributes were tokenized, preprocessed, and then vectorized using TFIDF vectorizer.\n",
        "*   Through TFIDF Vectorization, we created a total of 20000 attributes.\n",
        "*   We used Principal Component Analysis (PCA) to handle the curse of dimensionality. 4000 components were able to capture more than 80% of variance, and hence, the number of components were restricted to 4000.\n",
        "*   We first built clusters using the k-means clustering algorithm, and the optimal number of clusters came out to be 6. This was obtained through the elbow method and Silhouette score analysis.\n",
        "*   Then clusters were built using the Agglomerative clustering algorithm, and the optimal number of clusters came out to be 12. This was obtained after visualizing the dendrogram.\n",
        "*   A content based recommender system was built using the similarity matrix obtained after using cosine similarity. This recommender system will make 10 recommendations to the user based on the type of show they watched.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}